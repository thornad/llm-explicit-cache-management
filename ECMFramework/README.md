# ECMFramework

A Swift framework for **Explicit Cache Management** in Large Language Models, enabling user-controlled, prompt-level caching for efficient content reuse.

## Overview

ECMFramework allows users to explicitly cache and reference content through simple prompt directives, eliminating redundant computation when working with repeated content across multiple LLM queries.

### Key Features

- ‚úÖ **User-Controlled Caching**: Explicit cache directives in prompts
- ‚úÖ **Semantic Organization**: User-defined cache identifiers  
- ‚úÖ **Framework Agnostic**: Works with any LLM framework via protocol abstraction
- ‚úÖ **SwiftUI Integration**: ObservableObject support
- ‚úÖ **Memory Management**: Automatic cleanup and LRU eviction
- ‚úÖ **Error Handling**: Comprehensive error types and messages

## Quick Start

### Installation

#### Swift Package Manager
```swift
dependencies: [
    .package(url: "https://github.com/[username]/llm-explicit-cache-management", from: "1.0.0")
]
```

#### Xcode
1. File ‚Üí Add Package Dependencies
2. Enter: `https://github.com/[username]/llm-explicit-cache-management`
3. Select `ECMFramework`

### Basic Usage

#### 1. Create Context Adapter (for MLX)
```swift
import ECMFramework
import MLX
import MLXLLM

// Create adapter for your LLM framework
struct MLXContextAdapter: ECMModelContext {
    private let mlxContext: ModelContext
    
    init(_ context: ModelContext) {
        self.mlxContext = context
    }
    
    func encode(text: String) async throws -> [Int] {
        return try await mlxContext.tokenizer.encode(text: text)
    }
    
    func decode(tokens: [Int]) -> String {
        return mlxContext.tokenizer.decode(tokens: tokens)
    }
}
```

#### 2. Process Messages with ECM
```swift
// In your MLX service
let ecmContext = MLXContextAdapter(mlxModelContext)
let ecmResult = try await ECMFramework.shared.processMessage(userInput, context: ecmContext)

if ecmResult.hasCleanInput {
    // Use the assembled prompt for generation
    let response = try await generateResponse(ecmResult.finalPrompt, context: mlxModelContext)
} else {
    // Only cache operations, no generation needed
    print("‚úÖ Cache operation completed")
}
```

## Cache Directives

### Supported Operations

#### 1. Cache Storage
```
[System Cache: doc_id] Large document content here...
```

#### 2. Cache Reference  
```
Based on cache reference: doc_id, what is the main topic?
```

#### 3. Cache Cleanup
```
[System Clean Cache: doc_id]    // Clean specific cache
[System Clean Cache]            // Clean all caches
```

#### 4. Session Management
```
[System Start Session]
```

## API Reference

### ECMFramework

```swift
public class ECMFramework {
    public static let shared: ECMFramework
    
    // Process message with ECM directives
    public func processMessage<T: ECMModelContext>(_ message: String, 
                                                  context: T) async throws -> ECMResult
    
    // Get current cache status
    public var cacheStatus: ECMCacheStatus { get }
    
    // Clear all caches
    public func clearAllCaches()
}
```

### ECMModelContext Protocol

```swift
public protocol ECMModelContext {
    /// Encode text to tokens
    func encode(text: String) async throws -> [Int]
    
    /// Decode tokens to text  
    func decode(tokens: [Int]) -> String
}
```

### ECMResult

```swift
public struct ECMResult {
    public let directives: [CacheDirective]    // Parsed directives
    public let cleanInput: String              // Input without directives
    public let finalPrompt: String             // Assembled prompt for generation
    
    public var hasCacheOperations: Bool        // Has cache directives
    public var hasCleanInput: Bool             // Has content for generation
}
```

### ECMCacheStatus

```swift
public struct ECMCacheStatus {
    public let caches: [String: String]        // Cache ID -> Content
    public let stats: [String: Int]            // Cache ID -> Token count
    
    public var count: Int                      // Number of active caches
    public var isEmpty: Bool                   // No active caches
    
    // Get preview of cached content
    public func preview(for id: String, maxLength: Int = 100) -> String
}
```

## Framework Integration

ECMFramework uses a protocol-based architecture to work with any LLM framework. You just need to create an adapter:

### For MLX:
```swift
struct MLXContextAdapter: ECMModelContext {
    private let mlxContext: ModelContext
    
    init(_ context: ModelContext) { self.mlxContext = context }
    
    func encode(text: String) async throws -> [Int] {
        return try await mlxContext.tokenizer.encode(text: text)
    }
    
    func decode(tokens: [Int]) -> String {
        return mlxContext.tokenizer.decode(tokens: tokens)
    }
}
```

### For Other Frameworks:
Create similar adapters for Transformers, llama.cpp, or any other framework by implementing the `ECMModelContext` protocol.

## SwiftUI Integration

### Monitoring Cache Status

```swift
struct CacheStatusView: View {
    @ObservedObject private var cacheManager = ExplicitCacheManager.shared
    
    var body: some View {
        VStack {
            Text("Active Caches: \(cacheManager.caches.count)")
            
            ForEach(Array(cacheManager.caches.keys), id: \.self) { key in
                Text("\(key): \(cacheManager.cacheStats[key] ?? 0) tokens")
            }
            
            Button("Clear All") {
                ECMFramework.shared.clearAllCaches()
            }
        }
    }
}
```

## Error Handling

ECMFramework provides comprehensive error handling:

```swift
do {
    let result = try await ECMFramework.shared.processMessage(input, context: ecmContext)
    // Handle success
} catch ECMError.cacheNotFound(let id, let available) {
    print("Cache '\(id)' not found. Available: \(available)")
} catch ECMError.malformedDirective(let directive) {
    print("Invalid directive: \(directive)")
} catch ECMError.processingError(let message) {
    print("Processing error: \(message)")
}
```

## Performance Benefits

ECM provides substantial efficiency gains for repeated content:

- **Document Analysis**: N questions about a document require ~1√ó document processing + N query processing (vs N√ó document processing)
- **Code Review**: Multiple questions about a codebase eliminate repeated parsing
- **Educational Content**: Students benefit from persistent caching across sessions

Expected performance improvements:
- 75-95% reduction in token processing
- 6-9√ó faster response times
- Up to 90% reduction in API costs

## Thread Safety

ECMFramework is designed to be thread-safe:
- Cache operations use appropriate synchronization
- SwiftUI integration uses `@MainActor` where needed
- Concurrent access is handled safely

## Memory Management

The framework includes intelligent memory management:
- **LRU Eviction**: Least-recently-used caches are evicted first
- **Configurable Limits**: Set maximum cache size or token count
- **Manual Cleanup**: User-controlled cache clearing
- **Automatic Cleanup**: Memory pressure handling

## Testing

Run the test suite:

```bash
swift test
```

The framework includes comprehensive tests:
- ‚úÖ Directive parsing validation
- ‚úÖ Cache management operations
- ‚úÖ Error handling scenarios  
- ‚úÖ Edge cases and malformed input
- ‚úÖ Performance benchmarks

## Example Workflows

### Document Analysis
```swift
// 1. Cache a large document
"[System Cache: contract] [50,000 token legal contract...]"

// 2. Ask multiple questions efficiently  
"Based on cache reference: contract, what is the termination clause?"
"Based on cache reference: contract, what are the liability limits?"
"Based on cache reference: contract, when does this expire?"
```

### Code Review
```swift
// 1. Cache a large codebase
"[System Cache: codebase] [Large Swift project...]"

// 2. Review different aspects
"Based on cache reference: codebase, explain the authentication flow"
"Based on cache reference: codebase, identify potential security issues"
"Based on cache reference: codebase, suggest performance improvements"
```

## Requirements

- iOS 16.0+ / macOS 13.0+
- Swift 5.9+
- Your choice of LLM framework (MLX, Transformers, etc.)
- Xcode 15.0+

## Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## License

[Your chosen license]

## Support

- üìñ **Documentation**: See main repository docs
- üêõ **Issues**: GitHub Issues
- üí¨ **Discussions**: GitHub Discussions
- üìß **Contact**: [Your contact information]